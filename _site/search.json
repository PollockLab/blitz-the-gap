[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blitz the Gap",
    "section": "",
    "text": "Blitz the Gap is a Canada-wide bioblitz to help us fill gaps in our knowledge of biodiversity in Canada. Canada is a large country and hosts tons of amazing biodiversity - which makes it a challenging place to survey. Though we’ve made progress thanks to community science platforms like iNat, we are still lacking the data for a whole host of ecological and conservation applications. We need more data to assess at-risk species, track the changes in species’ ranges due to climate change, rapidly detect species losses and invasions, and more."
  },
  {
    "objectID": "index.html#ready-set-blitz-the-gap",
    "href": "index.html#ready-set-blitz-the-gap",
    "title": "Blitz the Gap",
    "section": "Ready? Set? Blitz the Gap!",
    "text": "Ready? Set? Blitz the Gap!"
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "Making priority maps for Blitz the Gap",
    "section": "",
    "text": "This is an example workflow to identify gaps in a biodiversity database (like GBIF or iNaturalist), and to generate raster maps where each cell is assigned a priority level for sampling in a bioblitz event.\nEach map will cross biodiversity priorities with accessibility to identify the cells that are easiest to sample while helping to fill a biodiversity data gap. Gaps will be defined based on “Challenges” that will be part of the Blitz the Gap event.\nHere, we will build an example challenge to encourage community scientists to update historical records of amphibians.\n\n\nLoad packages:\n\nlibrary(dplyr) \nlibrary(terra)\nlibrary(rgbif)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(mapview)\nlibrary(raster)\n\nSet some mapview options to apply to all the maps we will make here:\n\nmapviewOptions(basemaps = c( \"OpenStreetMap\"),\n               na.color = \"transparent\")\n\n\n\nLoad spatial layers that we will use to make sure all of our layers match (in terms of the grid resolution and projection).\n\n# Canada polygon\ncanada = sf::read_sf(\"data/raw/base-layers/canada-polygon/canada.outline.shp\")\n\n# Base grid for rasterizing\nbase.5k = terra::rast(\"data/raw/base-layers/canada.base.5k.tiff\")\n\n# Mask water and built areas\nbase.water &lt;- rast(\"data/raw/base-layers/WaterUrbanBuiltMask.tif\")\nbase.water&lt;-project(base.water,crs(base.5k))\nbase.water&lt;-resample(base.water,base.5k,method='near')\nterra::writeRaster(base.water, \"data/processed/base-layers/WaterUrbanBuiltMask.tif\")\n\n# Make a reverse of the base layer to remove cells that we don't want to consider (later)\nanti.base=base.5k\nanti.base[is.na(anti.base)] &lt;- 1\nanti.base[anti.base==2] &lt;- NA\nanti.base[base.water==1] &lt;- 1\nterra::writeRaster(anti.base, \"data/processed/base-layers/anti.base.5k.tif\")\n\n\n\n\nThis tutorial will use GBIF data, though later steps will be similarly useful to process iNaturalist data. Here, let’s use a download of all amphibian data in Canada.\n\n# Download the GBIF data through the GBIF data website. Make sure to save the citation details from the download in a text file alongside the data.\n# Unzip in the data/raw/gbif/your_taxa_of_choice folder\n# Read in the dataset and select columns we need\ngbif = data.table::fread(\"data/raw/gbif/amphibians/0007149-250127130748423.csv\") |&gt;\n  filter(coordinateUncertaintyInMeters &lt; 100000) |&gt;\n  select(family, scientificName, year,\n         decimalLongitude, decimalLatitude, coordinatePrecision,\n         datasetKey, basisOfRecord)\n\nFirst, we need to prepare the GBIF data into a spatial object:\n\n# Convert GBIF to a points layer\ngbif.v &lt;- vect(gbif,\n               geom=c(\"decimalLongitude\",\"decimalLatitude\"),\n             crs=\"+proj=longlat +ellps=WGS84\",\n             keepgeom = TRUE)\n\n# Project GBIF \ngbif.v &lt;- project(gbif.v, crs(base.5k))\n\n# Remove occurrences outside the canada polygon\ngbif.v = terra::crop(gbif.v, canada)\n\nNow we can convert the GBIF data into raster layers:\n\ngbif.density: count of GBIF observations per cell\nmuseum.density: count of GBIF observations from preserved specimens (museums) per cell\niNat.density: count of GBIF observations from iNaturalist (dataset key: \"50c9509d-22c7-4a22-a47d-8c48425ef4a7\") per cell\nyear.last.sampled: year of the last GBIF observation in GBIF per cell\n\n\n# Make a GBIF density layer\ngbif.density &lt;- rasterize(gbif.v, base.5k, fun=\"count\")\n\n# Density of museum observations\nmuseum.density &lt;- rasterize(gbif.v[which(gbif.v$basisOfRecord == \"PRESERVED_SPECIMEN\")], base.5k, fun=\"count\")\n\n# Density of observations from iNaturalist alone\niNat.density &lt;- rasterize(gbif.v[which(gbif.v$datasetKey == \"50c9509d-22c7-4a22-a47d-8c48425ef4a7\")], base.5k, fun=\"count\")\n\n# Raster of the latest observation's year\nyear.last.sampled &lt;- rasterize(gbif.v, base.5k, fun=\"max\", field=\"year\")\n\n# Stack the GBIF layers into one object for easy saving\ngbif.layers = c(gbif.density,museum.density,iNat.density,year.last.sampled)\nnames(gbif.layers) = c(\"gbif.density\",\"museum.density\",\"iNat.density\",\"year.last.sampled\")\ngbif.layers[is.na(base.5k)]&lt;-NA\n\n# save\nwriteRaster(gbif.layers,\"data/processed/gbif.layers.amphibians.tif\", overwrite = TRUE)\nwriteVector(gbif.v,\"data/processed/gbif.points.amphibians.shp\", overwrite = TRUE)\n\n\n\n\n\nMany of these layers are originally from the GEOBON STAC catalog, which can be viewed here: https://stac.geobon.org/viewer/. Instructions about how to retrieve these layers and download them for use are here: Working with STAC.\nThis is some code to reproject and resample the rasters from the STAC to match the GBIF density layers, after downloading them following the instructions linked above.\n\n\nClimate velocity (a metric of how quickly the climate will change by 2085 in each cell, under RCP85):\n\nvel &lt;- rast(\"data/raw/base-layers/climatevelocity_adaptwest_fwvel_ensemble_rcp85_2085.tif\")\nvel&lt;-project(vel,base.5k,\"bilinear\")\nvel&lt;-resample(vel,base.5k,method='near')\nvel[is.na(base.5k)] &lt;- NA\nterra::writeRaster(vel, \"data/processed/base-layers/climatevelocity_adaptwest_fwvel_ensemble_rcp85_2085.tif\")\n\n\n\n\nDistance to roads:\n\ndist.to.roads&lt;-rast(\"data/raw/base-layers/distance.to.roads.tif\")\ndist.to.roads&lt;-project(dist.to.roads,base.5k,\"bilinear\")\ndist.to.roads[is.na(base.5k)]&lt;-NA\nterra::writeRaster(dist.to.roads, \"data/processed/base-layers/dist.to.roads.tif\")\n\n\n\n\n\n\n\n\n# Copy the layer into a new object that we'll edit\nresamp &lt;- gbif.layers$year.last.sampled\nmapview(resamp, \n        na.color = \"transparent\")\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\nNext, we will assign priority values to cells based on the year they were last sampled. These are the priority levels we will use:\n\n\n\nPriority\nOldest observation\nNewest observation\n\n\n\n\nHigh (1)\noldest\n1950\n\n\nMedium (2)\n1951\n2000\n\n\nLow (3)\n2001\n2015\n\n\nNot a priority (4)\n2016\n2025\n\n\n\nLet’s assign these values based on the condition that the year last sampled in GBIF is within those year limits:\n\nresamp[gbif.layers$year.last.sampled &lt;= 1950] &lt;- 1\nresamp[gbif.layers$year.last.sampled &gt; 1950 & gbif.layers$year.last.sampled &lt;= 2000] &lt;- 2\nresamp[gbif.layers$year.last.sampled &gt; 2000 & gbif.layers$year.last.sampled &lt;= 2015] &lt;- 3\nresamp[gbif.layers$year.last.sampled &gt; 2015] &lt;- 4\n\nLet’s map this to see what we’re working with!\n\nmapview(resamp)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\n\n\n\nLet’s make a mask of the pixels we consider to be accessible. Let’s say anything within 10 km of a major road is potentially accessible, so we’re only interested in these cells:\n\nd10 = dist.to.roads\nd10[d10&gt;10000] &lt;- NA # assign NA to pixels that are over 10 km away from a major road\nmapview(d10)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\nNow, we can use this same condition (ignore anything where dist.to.roads &gt; 10000) to select cells from the priority layer that are accessible:\n\npal = viridis::viridis(n = 3, direction = -1)\npriority = resamp\npriority[dist.to.roads &gt; 10000] &lt;- NA\nmapview(priority, \n        col.regions = pal)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\n\n\n\nLet’s visualize this a little differently, so it is easier to explore. We will make a point layer with the year in which the cell was last sampled, and this layer is resized as we zoom in and out so it is easier to have a quick view of the map. When we zoom in, we will see the cell the point is referring to, so we make sure we’re still identifying the exact cell outline that we’d be asking people to go sample.\n\nlast.year = gbif.layers$year.last.sampled\nlast.year[priority &gt; 3] &lt;- NA\nlast.year[dist.to.roads &gt; 10000] &lt;- NA\n\nhistorical_pts = last.year |&gt;\n  raster::raster() |&gt;\n  raster::rasterToPoints(fun = function(x){x&lt;2016}, spatial = TRUE)\n\nhistorical_cells = priority |&gt;\n  raster::raster() |&gt;\n  raster::rasterToPolygons(fun = function(x){x &lt; 4})\n\npal = viridis::viridis(n = 3, direction = -1)\n(m = mapview(historical_cells, \n        legend = TRUE, \n        basemaps = \"OpenStreetMap\",  \n        col.regions = pal,\n        layer.name = \"Priority\") +\n  mapview(historical_pts,\n          col.regions = pal,\n          legend = FALSE, \n          layer.name = \"Year last \\nsampled\"))\n\nWarning: Found less unique colors (3) than unique zcol values (80)! \nInterpolating color vector to match number of zcol values.\n\n\n\n\n\n\n\nhtmlwidgets::saveWidget(m@map, \n                        file = \"challenges/maps/challenge1_map.html\", \n                        title = \"Revisit the past: Amphibians\")"
  },
  {
    "objectID": "tutorial.html#step-1.-prepare-gbif-data-and-make-density-layers",
    "href": "tutorial.html#step-1.-prepare-gbif-data-and-make-density-layers",
    "title": "Making priority maps for Blitz the Gap",
    "section": "",
    "text": "Load packages:\n\nlibrary(dplyr) \nlibrary(terra)\nlibrary(rgbif)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(mapview)\nlibrary(raster)\n\nSet some mapview options to apply to all the maps we will make here:\n\nmapviewOptions(basemaps = c( \"OpenStreetMap\"),\n               na.color = \"transparent\")\n\n\n\nLoad spatial layers that we will use to make sure all of our layers match (in terms of the grid resolution and projection).\n\n# Canada polygon\ncanada = sf::read_sf(\"data/raw/base-layers/canada-polygon/canada.outline.shp\")\n\n# Base grid for rasterizing\nbase.5k = terra::rast(\"data/raw/base-layers/canada.base.5k.tiff\")\n\n# Mask water and built areas\nbase.water &lt;- rast(\"data/raw/base-layers/WaterUrbanBuiltMask.tif\")\nbase.water&lt;-project(base.water,crs(base.5k))\nbase.water&lt;-resample(base.water,base.5k,method='near')\nterra::writeRaster(base.water, \"data/processed/base-layers/WaterUrbanBuiltMask.tif\")\n\n# Make a reverse of the base layer to remove cells that we don't want to consider (later)\nanti.base=base.5k\nanti.base[is.na(anti.base)] &lt;- 1\nanti.base[anti.base==2] &lt;- NA\nanti.base[base.water==1] &lt;- 1\nterra::writeRaster(anti.base, \"data/processed/base-layers/anti.base.5k.tif\")\n\n\n\n\nThis tutorial will use GBIF data, though later steps will be similarly useful to process iNaturalist data. Here, let’s use a download of all amphibian data in Canada.\n\n# Download the GBIF data through the GBIF data website. Make sure to save the citation details from the download in a text file alongside the data.\n# Unzip in the data/raw/gbif/your_taxa_of_choice folder\n# Read in the dataset and select columns we need\ngbif = data.table::fread(\"data/raw/gbif/amphibians/0007149-250127130748423.csv\") |&gt;\n  filter(coordinateUncertaintyInMeters &lt; 100000) |&gt;\n  select(family, scientificName, year,\n         decimalLongitude, decimalLatitude, coordinatePrecision,\n         datasetKey, basisOfRecord)\n\nFirst, we need to prepare the GBIF data into a spatial object:\n\n# Convert GBIF to a points layer\ngbif.v &lt;- vect(gbif,\n               geom=c(\"decimalLongitude\",\"decimalLatitude\"),\n             crs=\"+proj=longlat +ellps=WGS84\",\n             keepgeom = TRUE)\n\n# Project GBIF \ngbif.v &lt;- project(gbif.v, crs(base.5k))\n\n# Remove occurrences outside the canada polygon\ngbif.v = terra::crop(gbif.v, canada)\n\nNow we can convert the GBIF data into raster layers:\n\ngbif.density: count of GBIF observations per cell\nmuseum.density: count of GBIF observations from preserved specimens (museums) per cell\niNat.density: count of GBIF observations from iNaturalist (dataset key: \"50c9509d-22c7-4a22-a47d-8c48425ef4a7\") per cell\nyear.last.sampled: year of the last GBIF observation in GBIF per cell\n\n\n# Make a GBIF density layer\ngbif.density &lt;- rasterize(gbif.v, base.5k, fun=\"count\")\n\n# Density of museum observations\nmuseum.density &lt;- rasterize(gbif.v[which(gbif.v$basisOfRecord == \"PRESERVED_SPECIMEN\")], base.5k, fun=\"count\")\n\n# Density of observations from iNaturalist alone\niNat.density &lt;- rasterize(gbif.v[which(gbif.v$datasetKey == \"50c9509d-22c7-4a22-a47d-8c48425ef4a7\")], base.5k, fun=\"count\")\n\n# Raster of the latest observation's year\nyear.last.sampled &lt;- rasterize(gbif.v, base.5k, fun=\"max\", field=\"year\")\n\n# Stack the GBIF layers into one object for easy saving\ngbif.layers = c(gbif.density,museum.density,iNat.density,year.last.sampled)\nnames(gbif.layers) = c(\"gbif.density\",\"museum.density\",\"iNat.density\",\"year.last.sampled\")\ngbif.layers[is.na(base.5k)]&lt;-NA\n\n# save\nwriteRaster(gbif.layers,\"data/processed/gbif.layers.amphibians.tif\", overwrite = TRUE)\nwriteVector(gbif.v,\"data/processed/gbif.points.amphibians.shp\", overwrite = TRUE)"
  },
  {
    "objectID": "tutorial.html#step-2.-prepare-environmental-human-access-layers",
    "href": "tutorial.html#step-2.-prepare-environmental-human-access-layers",
    "title": "Making priority maps for Blitz the Gap",
    "section": "",
    "text": "Many of these layers are originally from the GEOBON STAC catalog, which can be viewed here: https://stac.geobon.org/viewer/. Instructions about how to retrieve these layers and download them for use are here: Working with STAC.\nThis is some code to reproject and resample the rasters from the STAC to match the GBIF density layers, after downloading them following the instructions linked above.\n\n\nClimate velocity (a metric of how quickly the climate will change by 2085 in each cell, under RCP85):\n\nvel &lt;- rast(\"data/raw/base-layers/climatevelocity_adaptwest_fwvel_ensemble_rcp85_2085.tif\")\nvel&lt;-project(vel,base.5k,\"bilinear\")\nvel&lt;-resample(vel,base.5k,method='near')\nvel[is.na(base.5k)] &lt;- NA\nterra::writeRaster(vel, \"data/processed/base-layers/climatevelocity_adaptwest_fwvel_ensemble_rcp85_2085.tif\")\n\n\n\n\nDistance to roads:\n\ndist.to.roads&lt;-rast(\"data/raw/base-layers/distance.to.roads.tif\")\ndist.to.roads&lt;-project(dist.to.roads,base.5k,\"bilinear\")\ndist.to.roads[is.na(base.5k)]&lt;-NA\nterra::writeRaster(dist.to.roads, \"data/processed/base-layers/dist.to.roads.tif\")"
  },
  {
    "objectID": "tutorial.html#step-3.-make-a-priority-map",
    "href": "tutorial.html#step-3.-make-a-priority-map",
    "title": "Making priority maps for Blitz the Gap",
    "section": "",
    "text": "# Copy the layer into a new object that we'll edit\nresamp &lt;- gbif.layers$year.last.sampled\nmapview(resamp, \n        na.color = \"transparent\")\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\nNext, we will assign priority values to cells based on the year they were last sampled. These are the priority levels we will use:\n\n\n\nPriority\nOldest observation\nNewest observation\n\n\n\n\nHigh (1)\noldest\n1950\n\n\nMedium (2)\n1951\n2000\n\n\nLow (3)\n2001\n2015\n\n\nNot a priority (4)\n2016\n2025\n\n\n\nLet’s assign these values based on the condition that the year last sampled in GBIF is within those year limits:\n\nresamp[gbif.layers$year.last.sampled &lt;= 1950] &lt;- 1\nresamp[gbif.layers$year.last.sampled &gt; 1950 & gbif.layers$year.last.sampled &lt;= 2000] &lt;- 2\nresamp[gbif.layers$year.last.sampled &gt; 2000 & gbif.layers$year.last.sampled &lt;= 2015] &lt;- 3\nresamp[gbif.layers$year.last.sampled &gt; 2015] &lt;- 4\n\nLet’s map this to see what we’re working with!\n\nmapview(resamp)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\n\n\n\nLet’s make a mask of the pixels we consider to be accessible. Let’s say anything within 10 km of a major road is potentially accessible, so we’re only interested in these cells:\n\nd10 = dist.to.roads\nd10[d10&gt;10000] &lt;- NA # assign NA to pixels that are over 10 km away from a major road\nmapview(d10)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\nNow, we can use this same condition (ignore anything where dist.to.roads &gt; 10000) to select cells from the priority layer that are accessible:\n\npal = viridis::viridis(n = 3, direction = -1)\npriority = resamp\npriority[dist.to.roads &gt; 10000] &lt;- NA\nmapview(priority, \n        col.regions = pal)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\n\n\n\nLet’s visualize this a little differently, so it is easier to explore. We will make a point layer with the year in which the cell was last sampled, and this layer is resized as we zoom in and out so it is easier to have a quick view of the map. When we zoom in, we will see the cell the point is referring to, so we make sure we’re still identifying the exact cell outline that we’d be asking people to go sample.\n\nlast.year = gbif.layers$year.last.sampled\nlast.year[priority &gt; 3] &lt;- NA\nlast.year[dist.to.roads &gt; 10000] &lt;- NA\n\nhistorical_pts = last.year |&gt;\n  raster::raster() |&gt;\n  raster::rasterToPoints(fun = function(x){x&lt;2016}, spatial = TRUE)\n\nhistorical_cells = priority |&gt;\n  raster::raster() |&gt;\n  raster::rasterToPolygons(fun = function(x){x &lt; 4})\n\npal = viridis::viridis(n = 3, direction = -1)\n(m = mapview(historical_cells, \n        legend = TRUE, \n        basemaps = \"OpenStreetMap\",  \n        col.regions = pal,\n        layer.name = \"Priority\") +\n  mapview(historical_pts,\n          col.regions = pal,\n          legend = FALSE, \n          layer.name = \"Year last \\nsampled\"))\n\nWarning: Found less unique colors (3) than unique zcol values (80)! \nInterpolating color vector to match number of zcol values.\n\n\n\n\n\n\n\nhtmlwidgets::saveWidget(m@map, \n                        file = \"challenges/maps/challenge1_map.html\", \n                        title = \"Revisit the past: Amphibians\")"
  },
  {
    "objectID": "challenges/challenge1_revisit-the-past.html",
    "href": "challenges/challenge1_revisit-the-past.html",
    "title": "Revisiting the past",
    "section": "",
    "text": "To understand biodiversity change, we need a record of biodiversity change. Join this challenge to help us bridge time gaps in biodiversity data!\nSome of the most valuable information we have from the past is from naturalists who spent hours in the field, looking for species they love. Unfortunately, fewer and fewer of us can invest our lives into observing nature in this way, though we may share a passion for nature and the outdoors. Gaps are appearing not just in space, but also in time: as data gets older, we become less certain that the species is still there. By revisiting past observations, we can better understand how biodiversity is changing to prevent biodiversity losses."
  },
  {
    "objectID": "challenges/challenge1_revisit-the-past.html#whats-the-problem",
    "href": "challenges/challenge1_revisit-the-past.html#whats-the-problem",
    "title": "Revisiting the past",
    "section": "",
    "text": "To understand biodiversity change, we need a record of biodiversity change. Join this challenge to help us bridge time gaps in biodiversity data!\nSome of the most valuable information we have from the past is from naturalists who spent hours in the field, looking for species they love. Unfortunately, fewer and fewer of us can invest our lives into observing nature in this way, though we may share a passion for nature and the outdoors. Gaps are appearing not just in space, but also in time: as data gets older, we become less certain that the species is still there. By revisiting past observations, we can better understand how biodiversity is changing to prevent biodiversity losses."
  },
  {
    "objectID": "challenges/challenge1_revisit-the-past.html#where-should-you-go",
    "href": "challenges/challenge1_revisit-the-past.html#where-should-you-go",
    "title": "Revisiting the past",
    "section": "Where should you go?",
    "text": "Where should you go?\nTo bridge this gap, we encourage you to revisit places that were sampled in the past. We’ve highlighted historically-sampled places that are close to roads for you to choose from, which you can see on these maps:"
  },
  {
    "objectID": "challenges/challenge1_revisit-the-past.html#amphibians",
    "href": "challenges/challenge1_revisit-the-past.html#amphibians",
    "title": "Revisiting the past",
    "section": "Amphibians",
    "text": "Amphibians"
  },
  {
    "objectID": "challenges/challenge1_revisit-the-past.html#who-created-this-challenge",
    "href": "challenges/challenge1_revisit-the-past.html#who-created-this-challenge",
    "title": "Revisiting the past",
    "section": "Who created this challenge?",
    "text": "Who created this challenge?\nThis challenge was the first one created for Blitz the Gap, designed by Laura Pollock, Isaac Eckert, Pierre Rogy, and Katherine Hébert. We are all part of the Quantitative Biodiversity Lab at McGill University led by Laura. We use data from sources like iNaturalist to build biodiversity models that help us understand and predict biodiversity and how it is changing."
  },
  {
    "objectID": "workflows.html",
    "href": "workflows.html",
    "title": "Workflows",
    "section": "",
    "text": "Here are some tutorials to access and analyse iNaturalist Canada data to make Blitz the Gap challenges.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccessing the STAC Catalogue\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaking priority maps for Blitz the Gap\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing the iNaturalist Canada parquet file\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workflows/tutorial.html",
    "href": "workflows/tutorial.html",
    "title": "Making priority maps for Blitz the Gap",
    "section": "",
    "text": "This is an example workflow to identify gaps in a biodiversity database (like GBIF or iNaturalist), and to generate raster maps where each cell is assigned a priority level for sampling in a bioblitz event.\nEach map will cross biodiversity priorities with accessibility to identify the cells that are easiest to sample while helping to fill a biodiversity data gap. Gaps will be defined based on “Challenges” that will be part of the Blitz the Gap event.\nHere, we will build an example challenge to encourage community scientists to update historical records of amphibians.\n\n\nLoad packages:\n\nlibrary(dplyr) \nlibrary(tidyr)\nlibrary(terra)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(mapview)\nlibrary(raster)\nlibrary(here)\n\nSet some mapview options to apply to all the maps we will make here:\n\nmapviewOptions(basemaps = c(\"OpenStreetMap\"),\n               na.color = \"transparent\")\n\n\n\nLoad spatial layers that we will use to make sure all of our layers match (in terms of the grid resolution and projection).\n\n# Canada polygon\ncanada = sf::read_sf(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/canada-polygon/canada.outline.shp\")\n\n# Base grid for rasterizing\nbase.5k = terra::rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/canada.base.5k.tiff\")\n\n# Mask water and built areas\nbase.water &lt;- rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/WaterUrbanBuiltMask.tif\")\nbase.water&lt;-project(base.water,crs(base.5k))\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\nbase.water&lt;-resample(base.water,base.5k,method='near')\nterra::writeRaster(base.water, here::here(\"data/clean/base-layers/WaterUrbanBuiltMask.tif\"), overwrite=TRUE)\n\n# Make a reverse of the base layer to remove cells that we don't want to consider (later)\nanti.base=base.5k\nanti.base[is.na(anti.base)] &lt;- 1\nanti.base[anti.base==2] &lt;- NA\nanti.base[base.water==1] &lt;- 1\nterra::writeRaster(anti.base, here::here(\"data/clean/base-layers/anti.base.5k.tif\"), overwrite = TRUE)\n\n\n\n\nThis tutorial will use GBIF data, though later steps will be similarly useful to process iNaturalist data. Here, let’s use a download of all amphibian data in Canada.\n\n# Download the GBIF data through the GBIF data website. Make sure to save the citation details from the download in a text file alongside the data.\n# Unzip in the data/raw/gbif/your_taxa_of_choice folder\n# Read in the dataset and select columns we need\ngbif = data.table::fread(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/biodiversity-data/amphibians/0007149-250127130748423.csv\") |&gt;\n  dplyr::filter(coordinateUncertaintyInMeters &lt; 100000) |&gt;\n  dplyr::select(family, scientificName, year,\n         decimalLongitude, decimalLatitude, coordinatePrecision,\n         datasetKey, basisOfRecord)\n\nWarning in data.table::fread(\"~/McGill University/Laura's Lab_Group -\nBioBlitz/data/raw/biodiversity-data/amphibians/0007149-250127130748423.csv\"):\nFound and resolved improper quoting out-of-sample. First healed line 22119:\n&lt;&lt;1698710821 bb5b30b4-827e-4d5e-a86a-825d65cb6583 pbdb:occ:707290 Animalia\nChordata Amphibia Caudata Cryptobranchidae Andrias Plicagnathus matthewi\nSPECIES Andrias matthewi (Cook, 1917) Andrias matthewi CA \"near Rockglen\"\n(basis of coordinate) Saskatchewan PRESENT b711353c-44d7-4e8b-90c5-16fea0d247e0\n49.183334 -105.949997 0.0166667 8630364 9248222 MATERIAL_CITATION PBDB 75873\nCC_BY_NC_4_0 Naylor 2024-04-23T18:40:43.316Z\nTAXON_MATCH_TAXON_ID_IGNORED;TAXON_MATCH_TAXON_CONCEPT_ID_&gt;&gt;. If the fields are\nnot quoted (e.g. field separator does not appear within any field), try\nquote=\"\" to avoid this warning.\n\n\nFirst, we need to prepare the GBIF data into a spatial object:\n\n# Convert GBIF to a points layer\ngbif.v &lt;- vect(gbif,\n               geom=c(\"decimalLongitude\",\"decimalLatitude\"),\n             crs=\"+proj=longlat +ellps=WGS84\",\n             keepgeom = TRUE)\n\n# Project GBIF \ngbif.v &lt;- project(gbif.v, crs(base.5k))\n\n# Remove occurrences outside the canada polygon\ngbif.v = terra::crop(gbif.v, canada)\n\nNow we can convert the GBIF data into raster layers:\n\ngbif.density: count of GBIF observations per cell\nmuseum.density: count of GBIF observations from preserved specimens (museums) per cell\niNat.density: count of GBIF observations from iNaturalist (dataset key: \"50c9509d-22c7-4a22-a47d-8c48425ef4a7\") per cell\nyear.last.sampled: year of the last GBIF observation in GBIF per cell\n\n\n# Make a GBIF density layer\ngbif.density &lt;- rasterize(gbif.v, base.5k, fun=\"count\")\n\n# Density of museum observations\nmuseum.density &lt;- rasterize(gbif.v[which(gbif.v$basisOfRecord == \"PRESERVED_SPECIMEN\")], base.5k, fun=\"count\")\n\n# Density of observations from iNaturalist alone\niNat.density &lt;- rasterize(gbif.v[which(gbif.v$datasetKey == \"50c9509d-22c7-4a22-a47d-8c48425ef4a7\")], base.5k, fun=\"count\")\n\n# Raster of the latest observation's year\nyear.last.sampled &lt;- rasterize(gbif.v, base.5k, fun=\"max\", field=\"year\")\n\n# Stack the GBIF layers into one object for easy saving\ngbif.layers = c(gbif.density,museum.density,iNat.density,year.last.sampled)\nnames(gbif.layers) = c(\"gbif.density\",\"museum.density\",\"iNat.density\",\"year.last.sampled\")\ngbif.layers[is.na(base.5k)]&lt;-NA\n\n# save\nwriteRaster(gbif.layers, here::here(\"data/clean/biodiversity-data/rasters/gbif.layers.amphibians.tif\"), overwrite = TRUE)\nwriteVector(gbif.v, here::here(\"data/clean/biodiversity-data/points/gbif.points.amphibians.shp\"), overwrite = TRUE)\n\n\n\n\n\nMany of these layers are originally from the GEOBON STAC catalog, which can be viewed here: https://stac.geobon.org/viewer/. Instructions about how to retrieve these layers and download them for use are here: Working with STAC.\nThis is some code to reproject and resample the rasters from the STAC to match the GBIF density layers, after downloading them following the instructions linked above.\n\n\nClimate velocity (a metric of how quickly the climate will change by 2085 in each cell, under RCP85):\n\nvel &lt;- rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/challenges/climate/climatevelocity_adaptwest_fwvel_ensemble_rcp85_2085.tif\")\nvel&lt;-project(vel,base.5k,\"bilinear\")\nvel&lt;-resample(vel,base.5k,method='near')\nvel[is.na(base.5k)] &lt;- NA\nterra::writeRaster(vel, here::here(\"data/clean/challenges/climate/climatevelocity_adaptwest_fwvel_ensemble_rcp85_2085.tif\"), overwrite=TRUE)\n\n\n\n\nDistance to roads:\n\ndist.to.roads&lt;-rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/distance.to.roads.tif\")\ndist.to.roads&lt;-project(dist.to.roads,base.5k,\"bilinear\")\ndist.to.roads[is.na(base.5k)]&lt;-NA\nterra::writeRaster(dist.to.roads, here::here(\"data/clean/base-layers/dist.to.roads.tif\"),overwrite = TRUE)\n\n\n\n\n\n\n\n\n# Copy the layer into a new object that we'll edit\nresamp &lt;- gbif.layers$year.last.sampled\nmapview(resamp, \n        na.color = \"transparent\")\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\nNext, we will assign priority values to cells based on the year they were last sampled. These are the priority levels we will use:\n\n\n\nPriority\nOldest observation\nNewest observation\n\n\n\n\nHigh (1)\noldest\n1950\n\n\nMedium (2)\n1951\n2000\n\n\nLow (3)\n2001\n2015\n\n\nNot a priority (4)\n2016\n2025\n\n\n\nLet’s assign these values based on the condition that the year last sampled in GBIF is within those year limits:\n\nresamp[gbif.layers$year.last.sampled &lt;= 1950] &lt;- 1\nresamp[gbif.layers$year.last.sampled &gt; 1950 & gbif.layers$year.last.sampled &lt;= 2000] &lt;- 2\nresamp[gbif.layers$year.last.sampled &gt; 2000 & gbif.layers$year.last.sampled &lt;= 2015] &lt;- 3\nresamp[gbif.layers$year.last.sampled &gt; 2015] &lt;- 4\n\nLet’s map this to see what we’re working with!\n\nmapview(resamp)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\n\n\n\nLet’s make a mask of the pixels we consider to be accessible. Let’s say anything within 10 km of a major road is potentially accessible, so we’re only interested in these cells:\n\nd10 = dist.to.roads\nd10[d10&gt;10000] &lt;- NA # assign NA to pixels that are over 10 km away from a major road\nmapview(d10)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\nNow, we can use this same condition (ignore anything where dist.to.roads &gt; 10000) to select cells from the priority layer that are accessible:\n\npal = viridis::viridis(n = 3, direction = -1)\npriority = resamp\npriority[dist.to.roads &gt; 10000] &lt;- NA\nmapview(priority, \n        col.regions = pal)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\n\n\n\nLet’s visualize this a little differently, so it is easier to explore. We will make a point layer with the year in which the cell was last sampled, and this layer is resized as we zoom in and out so it is easier to have a quick view of the map. When we zoom in, we will see the cell the point is referring to, so we make sure we’re still identifying the exact cell outline that we’d be asking people to go sample.\n\nlast.year = gbif.layers$year.last.sampled\nlast.year[priority &gt; 3] &lt;- NA\nlast.year[dist.to.roads &gt; 10000] &lt;- NA\n\nhistorical_pts = last.year |&gt;\n  raster::raster() |&gt;\n  raster::rasterToPoints(fun = function(x){x&lt;2016}, spatial = TRUE)\n\nhistorical_cells = priority |&gt;\n  raster::raster() |&gt;\n  raster::rasterToPolygons(fun = function(x){x &lt; 4})\n\npal = viridis::viridis(n = 3, direction = -1)\n(m = mapview(historical_cells, \n        legend = TRUE, \n        basemaps = \"OpenStreetMap\",  \n        col.regions = pal,\n        layer.name = \"Priority\") +\n  mapview(historical_pts,\n          col.regions = pal,\n          legend = FALSE, \n          layer.name = \"Year last \\nsampled\"))\n\nWarning: Found less unique colors (3) than unique zcol values (80)! \nInterpolating color vector to match number of zcol values.\n\n\n\n\n\n\n\nhtmlwidgets::saveWidget(m@map, \n                        file = here::here(\"challenges/maps/challenge1_map.html\"), \n                        title = \"Revisit the past: Amphibians\")"
  },
  {
    "objectID": "workflows/tutorial.html#step-1.-prepare-gbif-data-and-make-density-layers",
    "href": "workflows/tutorial.html#step-1.-prepare-gbif-data-and-make-density-layers",
    "title": "Making priority maps for Blitz the Gap",
    "section": "",
    "text": "Load packages:\n\nlibrary(dplyr) \nlibrary(tidyr)\nlibrary(terra)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(mapview)\nlibrary(raster)\nlibrary(here)\n\nSet some mapview options to apply to all the maps we will make here:\n\nmapviewOptions(basemaps = c(\"OpenStreetMap\"),\n               na.color = \"transparent\")\n\n\n\nLoad spatial layers that we will use to make sure all of our layers match (in terms of the grid resolution and projection).\n\n# Canada polygon\ncanada = sf::read_sf(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/canada-polygon/canada.outline.shp\")\n\n# Base grid for rasterizing\nbase.5k = terra::rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/canada.base.5k.tiff\")\n\n# Mask water and built areas\nbase.water &lt;- rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/WaterUrbanBuiltMask.tif\")\nbase.water&lt;-project(base.water,crs(base.5k))\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\nbase.water&lt;-resample(base.water,base.5k,method='near')\nterra::writeRaster(base.water, here::here(\"data/clean/base-layers/WaterUrbanBuiltMask.tif\"), overwrite=TRUE)\n\n# Make a reverse of the base layer to remove cells that we don't want to consider (later)\nanti.base=base.5k\nanti.base[is.na(anti.base)] &lt;- 1\nanti.base[anti.base==2] &lt;- NA\nanti.base[base.water==1] &lt;- 1\nterra::writeRaster(anti.base, here::here(\"data/clean/base-layers/anti.base.5k.tif\"), overwrite = TRUE)\n\n\n\n\nThis tutorial will use GBIF data, though later steps will be similarly useful to process iNaturalist data. Here, let’s use a download of all amphibian data in Canada.\n\n# Download the GBIF data through the GBIF data website. Make sure to save the citation details from the download in a text file alongside the data.\n# Unzip in the data/raw/gbif/your_taxa_of_choice folder\n# Read in the dataset and select columns we need\ngbif = data.table::fread(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/biodiversity-data/amphibians/0007149-250127130748423.csv\") |&gt;\n  dplyr::filter(coordinateUncertaintyInMeters &lt; 100000) |&gt;\n  dplyr::select(family, scientificName, year,\n         decimalLongitude, decimalLatitude, coordinatePrecision,\n         datasetKey, basisOfRecord)\n\nWarning in data.table::fread(\"~/McGill University/Laura's Lab_Group -\nBioBlitz/data/raw/biodiversity-data/amphibians/0007149-250127130748423.csv\"):\nFound and resolved improper quoting out-of-sample. First healed line 22119:\n&lt;&lt;1698710821 bb5b30b4-827e-4d5e-a86a-825d65cb6583 pbdb:occ:707290 Animalia\nChordata Amphibia Caudata Cryptobranchidae Andrias Plicagnathus matthewi\nSPECIES Andrias matthewi (Cook, 1917) Andrias matthewi CA \"near Rockglen\"\n(basis of coordinate) Saskatchewan PRESENT b711353c-44d7-4e8b-90c5-16fea0d247e0\n49.183334 -105.949997 0.0166667 8630364 9248222 MATERIAL_CITATION PBDB 75873\nCC_BY_NC_4_0 Naylor 2024-04-23T18:40:43.316Z\nTAXON_MATCH_TAXON_ID_IGNORED;TAXON_MATCH_TAXON_CONCEPT_ID_&gt;&gt;. If the fields are\nnot quoted (e.g. field separator does not appear within any field), try\nquote=\"\" to avoid this warning.\n\n\nFirst, we need to prepare the GBIF data into a spatial object:\n\n# Convert GBIF to a points layer\ngbif.v &lt;- vect(gbif,\n               geom=c(\"decimalLongitude\",\"decimalLatitude\"),\n             crs=\"+proj=longlat +ellps=WGS84\",\n             keepgeom = TRUE)\n\n# Project GBIF \ngbif.v &lt;- project(gbif.v, crs(base.5k))\n\n# Remove occurrences outside the canada polygon\ngbif.v = terra::crop(gbif.v, canada)\n\nNow we can convert the GBIF data into raster layers:\n\ngbif.density: count of GBIF observations per cell\nmuseum.density: count of GBIF observations from preserved specimens (museums) per cell\niNat.density: count of GBIF observations from iNaturalist (dataset key: \"50c9509d-22c7-4a22-a47d-8c48425ef4a7\") per cell\nyear.last.sampled: year of the last GBIF observation in GBIF per cell\n\n\n# Make a GBIF density layer\ngbif.density &lt;- rasterize(gbif.v, base.5k, fun=\"count\")\n\n# Density of museum observations\nmuseum.density &lt;- rasterize(gbif.v[which(gbif.v$basisOfRecord == \"PRESERVED_SPECIMEN\")], base.5k, fun=\"count\")\n\n# Density of observations from iNaturalist alone\niNat.density &lt;- rasterize(gbif.v[which(gbif.v$datasetKey == \"50c9509d-22c7-4a22-a47d-8c48425ef4a7\")], base.5k, fun=\"count\")\n\n# Raster of the latest observation's year\nyear.last.sampled &lt;- rasterize(gbif.v, base.5k, fun=\"max\", field=\"year\")\n\n# Stack the GBIF layers into one object for easy saving\ngbif.layers = c(gbif.density,museum.density,iNat.density,year.last.sampled)\nnames(gbif.layers) = c(\"gbif.density\",\"museum.density\",\"iNat.density\",\"year.last.sampled\")\ngbif.layers[is.na(base.5k)]&lt;-NA\n\n# save\nwriteRaster(gbif.layers, here::here(\"data/clean/biodiversity-data/rasters/gbif.layers.amphibians.tif\"), overwrite = TRUE)\nwriteVector(gbif.v, here::here(\"data/clean/biodiversity-data/points/gbif.points.amphibians.shp\"), overwrite = TRUE)"
  },
  {
    "objectID": "workflows/tutorial.html#step-2.-prepare-environmental-human-access-layers",
    "href": "workflows/tutorial.html#step-2.-prepare-environmental-human-access-layers",
    "title": "Making priority maps for Blitz the Gap",
    "section": "",
    "text": "Many of these layers are originally from the GEOBON STAC catalog, which can be viewed here: https://stac.geobon.org/viewer/. Instructions about how to retrieve these layers and download them for use are here: Working with STAC.\nThis is some code to reproject and resample the rasters from the STAC to match the GBIF density layers, after downloading them following the instructions linked above.\n\n\nClimate velocity (a metric of how quickly the climate will change by 2085 in each cell, under RCP85):\n\nvel &lt;- rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/challenges/climate/climatevelocity_adaptwest_fwvel_ensemble_rcp85_2085.tif\")\nvel&lt;-project(vel,base.5k,\"bilinear\")\nvel&lt;-resample(vel,base.5k,method='near')\nvel[is.na(base.5k)] &lt;- NA\nterra::writeRaster(vel, here::here(\"data/clean/challenges/climate/climatevelocity_adaptwest_fwvel_ensemble_rcp85_2085.tif\"), overwrite=TRUE)\n\n\n\n\nDistance to roads:\n\ndist.to.roads&lt;-rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/distance.to.roads.tif\")\ndist.to.roads&lt;-project(dist.to.roads,base.5k,\"bilinear\")\ndist.to.roads[is.na(base.5k)]&lt;-NA\nterra::writeRaster(dist.to.roads, here::here(\"data/clean/base-layers/dist.to.roads.tif\"),overwrite = TRUE)"
  },
  {
    "objectID": "workflows/tutorial.html#step-3.-make-a-priority-map",
    "href": "workflows/tutorial.html#step-3.-make-a-priority-map",
    "title": "Making priority maps for Blitz the Gap",
    "section": "",
    "text": "# Copy the layer into a new object that we'll edit\nresamp &lt;- gbif.layers$year.last.sampled\nmapview(resamp, \n        na.color = \"transparent\")\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\nNext, we will assign priority values to cells based on the year they were last sampled. These are the priority levels we will use:\n\n\n\nPriority\nOldest observation\nNewest observation\n\n\n\n\nHigh (1)\noldest\n1950\n\n\nMedium (2)\n1951\n2000\n\n\nLow (3)\n2001\n2015\n\n\nNot a priority (4)\n2016\n2025\n\n\n\nLet’s assign these values based on the condition that the year last sampled in GBIF is within those year limits:\n\nresamp[gbif.layers$year.last.sampled &lt;= 1950] &lt;- 1\nresamp[gbif.layers$year.last.sampled &gt; 1950 & gbif.layers$year.last.sampled &lt;= 2000] &lt;- 2\nresamp[gbif.layers$year.last.sampled &gt; 2000 & gbif.layers$year.last.sampled &lt;= 2015] &lt;- 3\nresamp[gbif.layers$year.last.sampled &gt; 2015] &lt;- 4\n\nLet’s map this to see what we’re working with!\n\nmapview(resamp)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\n\n\n\nLet’s make a mask of the pixels we consider to be accessible. Let’s say anything within 10 km of a major road is potentially accessible, so we’re only interested in these cells:\n\nd10 = dist.to.roads\nd10[d10&gt;10000] &lt;- NA # assign NA to pixels that are over 10 km away from a major road\nmapview(d10)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\nNow, we can use this same condition (ignore anything where dist.to.roads &gt; 10000) to select cells from the priority layer that are accessible:\n\npal = viridis::viridis(n = 3, direction = -1)\npriority = resamp\npriority[dist.to.roads &gt; 10000] &lt;- NA\nmapview(priority, \n        col.regions = pal)\n\nNumber of pixels is above 5e+05.Only about 5e+05 pixels will be shown.\nYou can increase the value of `maxpixels` to 986203 to avoid this.\n\n\n\n\n\n\n\n\n\nLet’s visualize this a little differently, so it is easier to explore. We will make a point layer with the year in which the cell was last sampled, and this layer is resized as we zoom in and out so it is easier to have a quick view of the map. When we zoom in, we will see the cell the point is referring to, so we make sure we’re still identifying the exact cell outline that we’d be asking people to go sample.\n\nlast.year = gbif.layers$year.last.sampled\nlast.year[priority &gt; 3] &lt;- NA\nlast.year[dist.to.roads &gt; 10000] &lt;- NA\n\nhistorical_pts = last.year |&gt;\n  raster::raster() |&gt;\n  raster::rasterToPoints(fun = function(x){x&lt;2016}, spatial = TRUE)\n\nhistorical_cells = priority |&gt;\n  raster::raster() |&gt;\n  raster::rasterToPolygons(fun = function(x){x &lt; 4})\n\npal = viridis::viridis(n = 3, direction = -1)\n(m = mapview(historical_cells, \n        legend = TRUE, \n        basemaps = \"OpenStreetMap\",  \n        col.regions = pal,\n        layer.name = \"Priority\") +\n  mapview(historical_pts,\n          col.regions = pal,\n          legend = FALSE, \n          layer.name = \"Year last \\nsampled\"))\n\nWarning: Found less unique colors (3) than unique zcol values (80)! \nInterpolating color vector to match number of zcol values.\n\n\n\n\n\n\n\nhtmlwidgets::saveWidget(m@map, \n                        file = here::here(\"challenges/maps/challenge1_map.html\"), \n                        title = \"Revisit the past: Amphibians\")"
  },
  {
    "objectID": "workflows/parquet-file.html",
    "href": "workflows/parquet-file.html",
    "title": "Using the iNaturalist Canada parquet file",
    "section": "",
    "text": "For this working group, iNaturalist Canada provided us their data as a parquet file. Parquet is an open source file format that compresses and encodes large datasets for more efficient data storage, and importantly, more efficient retrieval of informaiton within the dataset. This format makes data lighter to handle because it is column-oriented, rather than row-oriented like a CSV file (which quickly gets overwhelming when you have many rows!).\nThis little tutorial will show you how to open the parquet file if you would like to explore it yourself. As a reminder, we have already made density maps from this file, so you may not need to explore it (depending on the challenge you’d like to build)!\nFirst, load the R packages you will need to use to access the density map layers:\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(arrow)\n\n\nAttaching package: 'arrow'\n\n\nThe following object is masked from 'package:utils':\n\n    timestamp\n\nlibrary(dbplyr, warn.conflicts = FALSE)\nlibrary(duckdb)\n\nLoading required package: DBI\n\nlibrary(terra)\n\nterra 1.8.21\n\n\n\nAttaching package: 'terra'\n\n\nThe following object is masked from 'package:arrow':\n\n    buffer\n\nlibrary(mapview) # for interactive maps\n\n# set ggplot theme of choice\ntheme_set(ggpubr::theme_pubr())\n\n\n\nNext, we will open the parquet file using the package arrow:\n\ninat_pq &lt;- arrow::open_dataset(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/biodiversity-data/inat-canada/iNat_non_sensitive_data_Jan2025.parquet\")\n\nNote that this isn’t the same as loading iNaturalist Canada as a CSV in your R session. Here, we’re establishing a connection to the database so we can make queries for the data that we really want.\nTake a look at the columns that are available in the file. We’ll use these columns to query the data with dplyr later:\n\ninat_pq$schema\n\nSchema\nOBJECTID: int64\nid: int32\nobserved_on_string: string\nuser_login: string\nquality_grade: string\nlicense: string\nurl: string\ntag_list: string\ndescription: string\nnum_identification_agreements: int32\nnum_identification_disagreements: int32\ncaptive_cultivated: string\nlatitude: double\nlongitude: double\npositional_accuracy: int32\npublic_positional_accuracy: int32\ngeoprivacy: string\ntaxon_geoprivacy: string\ncoordinates_obscured: string\npositioning_method: string\npositioning_device: string\nplace_town_name: string\nplace_county_name: string\nplace_state_name: string\nplace_country_name: string\nplace_admin1_name: string\nplace_admin2_name: string\nspecies_guess: string\nscientific_name: string\ncommon_name: string\niconic_taxon_name: string\ngeometry: binary\n\nSee $metadata for additional Schema metadata\n\n\n\n\n\nNext, we’ll query the data we want, and we will finish the query with the collect() command to load the query’s result into this R session.\nHere, we’ll summarise the number of observations per species, per group using dplyr (but you can use other dplyr functions like filter() for example!)\n\nquery &lt;- inat_pq |&gt; \n  \n  # E.g. you could filter by species group:\n  # filter(iconic_taxon_name == \"Aves\") |&gt;\n  \n  # Summarise number of obs per species, per species group\n  group_by(iconic_taxon_name, scientific_name) |&gt;\n  summarize(total_obs = n()) |&gt; \n  \n  # load the query into our R session\n  collect()\n\nLet’s have a look at the distribution of the number of observations per species, per group. We’ll put a vertical line to show the 100 observations/species mark, which we’ll dive into soon.\n\nggplot(data = query) +\n  geom_density(aes(x = total_obs,\n                     fill = iconic_taxon_name),\n               alpha = .5, lwd = .1) +\n  geom_vline(xintercept = 100) +\n  scale_x_log10() +\n  labs(x = \"Number of observations per species\",\n       y = \"Density (of species)\",\n       fill = \"Species group\") +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\nLet’s summarise our initial query to the species group level, to see which groups have more samples:\n\nsummary_query = query |&gt;\n  group_by(iconic_taxon_name) |&gt;\n  summarise(total_obs = sum(total_obs),\n            median_obs = median(total_obs))\n\nThis is just a few lines of code to reorder the species group names according to the number of observations, for prettier plots:\n\nquery$iconic_taxon_name = factor(query$iconic_taxon_name,\n                                 levels = summary_query$iconic_taxon_name[order(summary_query$median_obs)])\nsummary_query$iconic_taxon_name = factor(summary_query$iconic_taxon_name,\n                                         levels = summary_query$iconic_taxon_name[order(summary_query$total_obs)])\n\nWhich groups have more total samples?\n\nggplot(data = summary_query) +\n  geom_bar(aes(y = iconic_taxon_name,\n               x = total_obs,\n               fill = iconic_taxon_name),\n           stat = \"identity\") +\n  theme(legend.position = \"none\") +\n  scale_x_log10()\n\n\n\n\n\n\n\n\n\n\n\nSpecies with under 100 observations are of special interest to iNaturalist, so let’s have a look at which species have fewer than 100 observations.\nFirst, let’s filter our initial query to only retain species with &lt; 100 observations. Here, I removed species with &lt; 5 observations to get rid of some species with mistakes in their names, or that were just higher-level classes, etc. (But you can remove this condition too to make sure you’ve got everything).\n\nquery_under100 = query |&gt;\n  filter(total_obs &lt; 100 & total_obs &gt; 5)\n\nHow many species in each group have fewer than 100 observations?\n\nquery_under100 |&gt; \n  group_by(iconic_taxon_name) |&gt; \n  summarise(nsp = n_distinct(scientific_name)) \n\n# A tibble: 14 × 2\n   iconic_taxon_name   nsp\n   &lt;fct&gt;             &lt;int&gt;\n 1 Protozoa            159\n 2 Chromista           240\n 3 Actinopterygii      350\n 4 Reptilia             68\n 5 Mollusca            577\n 6 Amphibia             37\n 7 Animalia           1246\n 8 Arachnida           559\n 9 Mammalia            284\n10 Fungi              3045\n11 Aves                577\n12 Insecta            9484\n13 Plantae            5781\n14 &lt;NA&gt;                 91\n\n\nLet’s have a look at the number of observations per species for these under-sampled species.\n\nggplot(data = query_under100) +\n  geom_histogram(aes(x = total_obs, \n                          fill = iconic_taxon_name),\n                 bins = 10) +\n  theme(legend.position = \"none\") +\n  facet_wrap(~iconic_taxon_name, ncol = 2) +\n  labs(x = \"Number of observations per species\", \n       y = \"Number of species\") \n\n\n\n\n\n\n\n\nWe can see that for groups like fungi, insects and plants, there are many species with less than 30 observations!\n\nquery_under100 |&gt; group_by(iconic_taxon_name) |&gt; summarise(nsp = n_distinct(scientific_name))\n\n# A tibble: 14 × 2\n   iconic_taxon_name   nsp\n   &lt;fct&gt;             &lt;int&gt;\n 1 Protozoa            159\n 2 Chromista           240\n 3 Actinopterygii      350\n 4 Reptilia             68\n 5 Mollusca            577\n 6 Amphibia             37\n 7 Animalia           1246\n 8 Arachnida           559\n 9 Mammalia            284\n10 Fungi              3045\n11 Aves                577\n12 Insecta            9484\n13 Plantae            5781\n14 &lt;NA&gt;                 91\n\n\n\n\n\nLet’s make the iNaturalist query into a spatial object. First, we’ll make a vector layer, which we’ll then transform into a raster layer.\nFor the example, we’ll only do this for plants:\n\nobs &lt;- inat_pq |&gt;\n  # filter to plant species with &lt; 100 observations:\n  filter(scientific_name %in% query_under100$scientific_name,\n         iconic_taxon_name %in% \"Plantae\") |&gt;\n  # select columns we want to keep\n  select(c(longitude, latitude, \n           iconic_taxon_name, \n           scientific_name, \n           coordinates_obscured)) |&gt;\n  collect()\n\nNext, we need the polygon of Canada and a base grid that we’ll use to make our raster.\n\n# Load Canada polygon\ncanada = sf::read_sf(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/canada-polygon/canada.outline.shp\")\n\n# Read in base grid layer to make the raster\nbase.50k = terra::rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/canada.base.5k.tiff\") |&gt;\n  # convert to a coarser resolution for this example\n  terra::aggregate(fact = 10)\n\nNext, we convert the iNaturalist data to a vector layer and make sure to project it and to crop out any points that are not within Canada (just in case):\n\n# convert the iNaturalist ob\ninat.v = terra::vect(obs, geom = c(\"longitude\",\"latitude\"),\n             crs=\"+proj=longlat +ellps=WGS84\")\n# project to match the base grid\ninat.v = terra::project(inat.v, crs(base.50k))\n# crop observations outside of Canada\ninat.v = terra::crop(inat.v, canada)\n\nNow we can convert this vector into a raster of the density of observations of plant species that have &lt; 100 observations in Canada:\n\n# make iNat density layer\nrareplant.density = rasterize(inat.v, base.50k, fun = \"length\")\n\n# plot it!\npal = viridis::turbo(5)\nmapview(rareplant.density, \n        col.regions = pal,\n        layer.name = \"Density\")"
  },
  {
    "objectID": "workflows/parquet-file.html#open-the-parquet-file",
    "href": "workflows/parquet-file.html#open-the-parquet-file",
    "title": "Using the iNaturalist Canada parquet file",
    "section": "",
    "text": "Next, we will open the parquet file using the package arrow:\n\ninat_pq &lt;- arrow::open_dataset(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/biodiversity-data/inat-canada/iNat_non_sensitive_data_Jan2025.parquet\")\n\nNote that this isn’t the same as loading iNaturalist Canada as a CSV in your R session. Here, we’re establishing a connection to the database so we can make queries for the data that we really want.\nTake a look at the columns that are available in the file. We’ll use these columns to query the data with dplyr later:\n\ninat_pq$schema\n\nSchema\nOBJECTID: int64\nid: int32\nobserved_on_string: string\nuser_login: string\nquality_grade: string\nlicense: string\nurl: string\ntag_list: string\ndescription: string\nnum_identification_agreements: int32\nnum_identification_disagreements: int32\ncaptive_cultivated: string\nlatitude: double\nlongitude: double\npositional_accuracy: int32\npublic_positional_accuracy: int32\ngeoprivacy: string\ntaxon_geoprivacy: string\ncoordinates_obscured: string\npositioning_method: string\npositioning_device: string\nplace_town_name: string\nplace_county_name: string\nplace_state_name: string\nplace_country_name: string\nplace_admin1_name: string\nplace_admin2_name: string\nspecies_guess: string\nscientific_name: string\ncommon_name: string\niconic_taxon_name: string\ngeometry: binary\n\nSee $metadata for additional Schema metadata"
  },
  {
    "objectID": "workflows/parquet-file.html#query-the-data",
    "href": "workflows/parquet-file.html#query-the-data",
    "title": "Using the iNaturalist Canada parquet file",
    "section": "",
    "text": "Next, we’ll query the data we want, and we will finish the query with the collect() command to load the query’s result into this R session.\nHere, we’ll summarise the number of observations per species, per group using dplyr (but you can use other dplyr functions like filter() for example!)\n\nquery &lt;- inat_pq |&gt; \n  \n  # E.g. you could filter by species group:\n  # filter(iconic_taxon_name == \"Aves\") |&gt;\n  \n  # Summarise number of obs per species, per species group\n  group_by(iconic_taxon_name, scientific_name) |&gt;\n  summarize(total_obs = n()) |&gt; \n  \n  # load the query into our R session\n  collect()\n\nLet’s have a look at the distribution of the number of observations per species, per group. We’ll put a vertical line to show the 100 observations/species mark, which we’ll dive into soon.\n\nggplot(data = query) +\n  geom_density(aes(x = total_obs,\n                     fill = iconic_taxon_name),\n               alpha = .5, lwd = .1) +\n  geom_vline(xintercept = 100) +\n  scale_x_log10() +\n  labs(x = \"Number of observations per species\",\n       y = \"Density (of species)\",\n       fill = \"Species group\") +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\nLet’s summarise our initial query to the species group level, to see which groups have more samples:\n\nsummary_query = query |&gt;\n  group_by(iconic_taxon_name) |&gt;\n  summarise(total_obs = sum(total_obs),\n            median_obs = median(total_obs))\n\nThis is just a few lines of code to reorder the species group names according to the number of observations, for prettier plots:\n\nquery$iconic_taxon_name = factor(query$iconic_taxon_name,\n                                 levels = summary_query$iconic_taxon_name[order(summary_query$median_obs)])\nsummary_query$iconic_taxon_name = factor(summary_query$iconic_taxon_name,\n                                         levels = summary_query$iconic_taxon_name[order(summary_query$total_obs)])\n\nWhich groups have more total samples?\n\nggplot(data = summary_query) +\n  geom_bar(aes(y = iconic_taxon_name,\n               x = total_obs,\n               fill = iconic_taxon_name),\n           stat = \"identity\") +\n  theme(legend.position = \"none\") +\n  scale_x_log10()"
  },
  {
    "objectID": "workflows/parquet-file.html#which-species-have-100-observations",
    "href": "workflows/parquet-file.html#which-species-have-100-observations",
    "title": "Using the iNaturalist Canada parquet file",
    "section": "",
    "text": "Species with under 100 observations are of special interest to iNaturalist, so let’s have a look at which species have fewer than 100 observations.\nFirst, let’s filter our initial query to only retain species with &lt; 100 observations. Here, I removed species with &lt; 5 observations to get rid of some species with mistakes in their names, or that were just higher-level classes, etc. (But you can remove this condition too to make sure you’ve got everything).\n\nquery_under100 = query |&gt;\n  filter(total_obs &lt; 100 & total_obs &gt; 5)\n\nHow many species in each group have fewer than 100 observations?\n\nquery_under100 |&gt; \n  group_by(iconic_taxon_name) |&gt; \n  summarise(nsp = n_distinct(scientific_name)) \n\n# A tibble: 14 × 2\n   iconic_taxon_name   nsp\n   &lt;fct&gt;             &lt;int&gt;\n 1 Protozoa            159\n 2 Chromista           240\n 3 Actinopterygii      350\n 4 Reptilia             68\n 5 Mollusca            577\n 6 Amphibia             37\n 7 Animalia           1246\n 8 Arachnida           559\n 9 Mammalia            284\n10 Fungi              3045\n11 Aves                577\n12 Insecta            9484\n13 Plantae            5781\n14 &lt;NA&gt;                 91\n\n\nLet’s have a look at the number of observations per species for these under-sampled species.\n\nggplot(data = query_under100) +\n  geom_histogram(aes(x = total_obs, \n                          fill = iconic_taxon_name),\n                 bins = 10) +\n  theme(legend.position = \"none\") +\n  facet_wrap(~iconic_taxon_name, ncol = 2) +\n  labs(x = \"Number of observations per species\", \n       y = \"Number of species\") \n\n\n\n\n\n\n\n\nWe can see that for groups like fungi, insects and plants, there are many species with less than 30 observations!\n\nquery_under100 |&gt; group_by(iconic_taxon_name) |&gt; summarise(nsp = n_distinct(scientific_name))\n\n# A tibble: 14 × 2\n   iconic_taxon_name   nsp\n   &lt;fct&gt;             &lt;int&gt;\n 1 Protozoa            159\n 2 Chromista           240\n 3 Actinopterygii      350\n 4 Reptilia             68\n 5 Mollusca            577\n 6 Amphibia             37\n 7 Animalia           1246\n 8 Arachnida           559\n 9 Mammalia            284\n10 Fungi              3045\n11 Aves                577\n12 Insecta            9484\n13 Plantae            5781\n14 &lt;NA&gt;                 91"
  },
  {
    "objectID": "workflows/parquet-file.html#convert-the-parquet-query-into-a-vector-and-a-raster-layer",
    "href": "workflows/parquet-file.html#convert-the-parquet-query-into-a-vector-and-a-raster-layer",
    "title": "Using the iNaturalist Canada parquet file",
    "section": "",
    "text": "Let’s make the iNaturalist query into a spatial object. First, we’ll make a vector layer, which we’ll then transform into a raster layer.\nFor the example, we’ll only do this for plants:\n\nobs &lt;- inat_pq |&gt;\n  # filter to plant species with &lt; 100 observations:\n  filter(scientific_name %in% query_under100$scientific_name,\n         iconic_taxon_name %in% \"Plantae\") |&gt;\n  # select columns we want to keep\n  select(c(longitude, latitude, \n           iconic_taxon_name, \n           scientific_name, \n           coordinates_obscured)) |&gt;\n  collect()\n\nNext, we need the polygon of Canada and a base grid that we’ll use to make our raster.\n\n# Load Canada polygon\ncanada = sf::read_sf(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/canada-polygon/canada.outline.shp\")\n\n# Read in base grid layer to make the raster\nbase.50k = terra::rast(\"~/McGill University/Laura's Lab_Group - BioBlitz/data/raw/base-layers/canada.base.5k.tiff\") |&gt;\n  # convert to a coarser resolution for this example\n  terra::aggregate(fact = 10)\n\nNext, we convert the iNaturalist data to a vector layer and make sure to project it and to crop out any points that are not within Canada (just in case):\n\n# convert the iNaturalist ob\ninat.v = terra::vect(obs, geom = c(\"longitude\",\"latitude\"),\n             crs=\"+proj=longlat +ellps=WGS84\")\n# project to match the base grid\ninat.v = terra::project(inat.v, crs(base.50k))\n# crop observations outside of Canada\ninat.v = terra::crop(inat.v, canada)\n\nNow we can convert this vector into a raster of the density of observations of plant species that have &lt; 100 observations in Canada:\n\n# make iNat density layer\nrareplant.density = rasterize(inat.v, base.50k, fun = \"length\")\n\n# plot it!\npal = viridis::turbo(5)\nmapview(rareplant.density, \n        col.regions = pal,\n        layer.name = \"Density\")"
  }
]